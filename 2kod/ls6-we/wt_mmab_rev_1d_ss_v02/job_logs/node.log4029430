Resetting modules to system default. Resetting $MODULEPATH back to system default. All extra directories will be removed from $MODULEPATH.
BEGIN INSIDE ENV.SH

Currently Loaded Modules:
  1) autotools/1.4   7) impi/19.0.9          13) swig/4.1.1_b
  2) cmake/3.24.2    8) cuda/11.3       (g)  14) boost/1.72.0_a
  3) pmix/3.2.3      9) conda/4.12.0_a       15) amber/22_a
  4) xalt/2.10.32   10) envwestpa/1.0_b      16) westpa/22.06_b
  5) TACC           11) fftw/3.3.10_a
  6) intel/19.1.1   12) openmm/7.7.0_a

  Where:
   g:  built for GPU

 

/work/09416/dty7/ls6/module_build_we_amber/modules/envwestpa/1.0_b/bin/python
END   INSIDE ENV.SH
starting WEST client processes on: 
c301-002.ls6.tacc.utexas.edu
current directory is /home1/09416/dty7/scratch/d1d2/2kod/ls6-we/wt_mmab_rev_1d_ss_v02
environment is: 
CUDA_VISIBLE_DEVICES =  0,1,2
-- INFO     [westpa.rc] -- loading system driver 'westpa.core.systems.WESTSystem'
-- INFO     [westpa.rc] -- Loading system options from configuration file
Updating system with the options from the configuration file
-- INFO     [westpa.rc] -- Overwriting system option: pcoord_ndim
-- INFO     [westpa.rc] -- Overwriting system option: pcoord_len
-- INFO     [westpa.rc] -- Overwriting system option: pcoord_dtype
-- INFO     [westpa.rc] -- Overwriting system option: bin_mapper
-- INFO     [westpa.rc] -- Overwriting system option: bin_target_counts
-- INFO     [westpa.core.we_driver] -- Adjust counts to exactly match target_counts: True
-- INFO     [westpa.core.we_driver] -- Obey abolute weight thresholds: True
-- INFO     [westpa.core.we_driver] -- Split threshold: 2.0
-- INFO     [westpa.core.we_driver] -- Merge cutoff: 1.0
-- INFO     [westpa.core.we_driver] -- Largest allowed weight: 1.0
-- INFO     [westpa.core.we_driver] -- Smallest allowed_weight: 1e-310
-- INFO     [westpa.work_managers.zeromq.core.ZMQWorker.bcb1017e-6416-4b04-b574-d0dcf580e675] -- This is ZMQWorker on c301-002.ls6.tacc.utexas.edu at PID 957100
-- INFO     [westpa.work_managers.zeromq.core.ZMQWorker.86b770ca-f67b-4b5f-8769-68b00366cb0c] -- This is ZMQWorker on c301-002.ls6.tacc.utexas.edu at PID 957100
-- INFO     [westpa.work_managers.zeromq.core.ZMQExecutor.3cce77f0-f12b-40f2-809d-413082702095] -- This is ZMQExecutor on c301-002.ls6.tacc.utexas.edu at PID 957109
-- INFO     [westpa.work_managers.zeromq.core.ZMQExecutor.8d1d674a-b4ff-497e-9b3e-3ddfadab1922] -- This is ZMQExecutor on c301-002.ls6.tacc.utexas.edu at PID 957102
-- INFO     [westpa.work_managers.zeromq.core.ZMQWorker.1c7ed2e7-f2a5-46a0-b792-329b7fc1d89f] -- This is ZMQWorker on c301-002.ls6.tacc.utexas.edu at PID 957100
-- INFO     [westpa.work_managers.zeromq.core.ZMQExecutor.30f4f12e-2f7f-488e-bd56-35c6adcc69b1] -- This is ZMQExecutor on c301-002.ls6.tacc.utexas.edu at PID 957116
-- WARNING  [westpa.work_managers.zeromq.core] -- sending SIGKILL to worker process 957102
-- WARN-- WARNING  [westpa.work_managers.zeromq.core] -- sending SIGKILL to worker process -- WARNI-- WARNING  [westpa.work_managers.zeromq.core] -- sending SIGKILL to worker processShutting down.  Hopefully this was on purpose?
purpose?
